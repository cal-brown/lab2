{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ce1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfbbd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supports_vectorized(itemsets, matrix, minSup=0):\n",
    "    supports_dict = {iset: 0 for iset in itemsets}\n",
    "    for iset in itemsets:\n",
    "        supports_dict[iset] = sum(reduce((lambda x,y: x&y), [matrix[item] for item in iset]))\n",
    "    rm_list = []\n",
    "    for iset in supports_dict.keys():\n",
    "        if supports_dict[iset] < minSup:\n",
    "            rm_list.append(iset)\n",
    "    for iset in rm_list:\n",
    "        supports_dict.pop(iset)\n",
    "    return supports_dict\n",
    "    #occurence_col = matrix[itemset[0]]\n",
    "    #for i in range(1, len(itemset)):\n",
    "    #    occurence_col = occurence_col & matrix[itemset[i]]\n",
    "    #return sum(occurence_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "956d95a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supports(itemsets, matrix, minSup=0):\n",
    "    supports_dict = {iset: 0 for iset in itemsets}\n",
    "    for idx in matrix.index:\n",
    "        for iset in itemsets:\n",
    "            row = matrix.loc[idx]\n",
    "            if reduce((lambda x,y: x&y), [row[item] for item in iset]) == 1:\n",
    "                supports_dict[iset] += 1\n",
    "    rm_list = []\n",
    "    for iset in supports_dict.keys():\n",
    "        if supports_dict[iset] < minSup:\n",
    "            rm_list.append(iset)\n",
    "    for iset in rm_list:\n",
    "        supports_dict.pop(iset)\n",
    "    return supports_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1742ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset_one_less(iterable):\n",
    "    sets = []\n",
    "    s = list(iterable)\n",
    "    for i in range(len(iterable)):\n",
    "        sets.append(frozenset(s[0:i]+s[i+1:]))\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b5454aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_gen(set_list):\n",
    "    C = []\n",
    "    for f1 in set_list:\n",
    "        for f2 in set_list:\n",
    "            if len(f1.union(f2)) == len(f1) + 1:\n",
    "                c = f1.union(f2)\n",
    "                if c not in C:\n",
    "                    flag = True\n",
    "                    for subset in powerset_one_less(c):\n",
    "                        if subset != f1 and subset != f2 and subset not in set_list:\n",
    "                            flag = False\n",
    "                    if flag:\n",
    "                        C.append(c)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b671c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(matrix, total_itemset, minRelativeSup):\n",
    "    all_supports_dict = {}\n",
    "    skylines = {}\n",
    "    minSup = minRelativeSup*matrix.shape[0]\n",
    "    all_supports_dict[1] = supports_vectorized([frozenset([i]) for i in total_itemset], matrix, minSup)\n",
    "    for singleton in all_supports_dict[1]:\n",
    "        skylines[singleton] = 1\n",
    "    k = 2\n",
    "    while(k <= len(total_itemset) and len(all_supports_dict[k-1].values()) > 0):\n",
    "        C_k = candidate_gen(all_supports_dict[k-1])\n",
    "        all_supports_dict[k] = supports_vectorized(C_k, matrix, minSup)\n",
    "        for ilist in all_supports_dict[k]:\n",
    "            skylines[ilist] = 1\n",
    "            for subset in powerset_one_less(ilist):\n",
    "                skylines[subset] = 0\n",
    "        k += 1\n",
    "    skyline_list = []\n",
    "    for itemset in skylines.keys():\n",
    "        if skylines[itemset] == 1:\n",
    "            skyline_list.append(itemset)\n",
    "    return all_supports_dict, skyline_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fe5ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_rules(supports_dict, skyline_list, minConfidence = 0, verbose=False):\n",
    "    confidence_dict = {}\n",
    "    for iset in skyline_list:\n",
    "        if (len(iset) >= 2):\n",
    "            for item in iset:\n",
    "                right_set = frozenset([item])\n",
    "                left_set = iset.difference(right_set)\n",
    "                total_support = supports_dict[len(iset)][iset]\n",
    "                left_support = supports_dict[len(left_set)][left_set]\n",
    "                confidence = total_support/left_support\n",
    "                if confidence > minConfidence:\n",
    "                    confidence_dict[(left_set, item)] = confidence\n",
    "    return confidence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46cbddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goods_lookup(item_id, goods):\n",
    "    row = goods.loc[item_id]\n",
    "    return row[\"Flavor\"][1:-1] + \" \" + row[\"Food\"][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c616afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_bakery_rules(filename, minRelativeSup, minConf, goods_filename, output_file=''):\n",
    "    #reading in goods and bakery datasets\n",
    "    goods = pd.read_csv(goods_filename)\n",
    "    bakery = pd.read_csv(filename, names=goods.index)\n",
    "    \n",
    "    #apriori and association rules\n",
    "    supports_dict,skyline_list = apriori(bakery, list(goods.index), minRelativeSup)\n",
    "    association_rules_dict = association_rules(supports_dict, skyline_list, minConf)\n",
    "    \n",
    "    if output_file != '':\n",
    "        #formatting skyline frequent item sets\n",
    "        skylines_formatted = []\n",
    "        for entry in skyline_list:\n",
    "            skyline_set = [goods_lookup(i, goods) for i in entry]\n",
    "            support = supports_dict[len(entry)][entry]/bakery.shape[0]\n",
    "            skylines_formatted.append((skyline_set, support))\n",
    "\n",
    "        #formatting association rules\n",
    "        arules_formatted = []\n",
    "        for entry in association_rules_dict.keys():\n",
    "            left_side = [goods_lookup(i, goods) for i in entry[0]]\n",
    "            right_side = goods_lookup(entry[1], goods)\n",
    "            full_itemset = entry[0].union([entry[1]])\n",
    "            support = supports_dict[len(full_itemset)][full_itemset]/bakery.shape[0]\n",
    "            confidence = association_rules_dict[entry]\n",
    "            arules_formatted.append((left_side, right_side, support, confidence))\n",
    "        \n",
    "        f = open(output_file, \"w\")\n",
    "        f.write(\"Skyline Frequent Item Sets: \\n\")\n",
    "        for skyline in skylines_formatted:\n",
    "            f.write(\"{}, support={}\\n\".format(skyline[0], skyline[1]))\n",
    "        f.write(\"\\nAssociation Rules:\\n\")\n",
    "        i = 1\n",
    "        for arule in arules_formatted:\n",
    "            f.write(\"Rule {}, {} -> {} [support={}, confidence={}]\\n\"\\\n",
    "                    .format(i, arule[0], arule[1], arule, confidence))\n",
    "        f.close()\n",
    "    return \"{} Skyline, {} A-Rules\"\\\n",
    "                .format(len(skyline_list), len(association_rules_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12f1f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in [\"5000\",  \"20000\", \"75000\"]:\n",
    "        mine_bakery_rules(size+\"-out2.csv\", .02, .9, \"goods.csv\", size+\"-output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d31cfdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skylines:\n",
      "\n",
      "(['Lemon Cake', 'Single Espresso'], 0.127)\n",
      "(['Napoleon Cake', 'Gongolais Cookie'], 0.181)\n",
      "(['Apple Danish', 'Blackberry Tart'], 0.139)\n",
      "(['Blueberry Tart', 'Apple Tart', 'Berry Tart'], 0.257)\n",
      "\n",
      "Association Rules:\n",
      "\n",
      "(['Single Espresso'], 'Lemon Cake', 0.127, 0.7839506172839507)\n",
      "(['Lemon Cake'], 'Single Espresso', 0.127, 0.8141025641025641)\n",
      "(['Gongolais Cookie'], 'Napoleon Cake', 0.181, 0.8418604651162791)\n",
      "(['Napoleon Cake'], 'Gongolais Cookie', 0.181, 0.8044444444444444)\n",
      "(['Blackberry Tart'], 'Apple Danish', 0.139, 0.7513513513513513)\n",
      "(['Apple Danish'], 'Blackberry Tart', 0.139, 0.7988505747126436)\n",
      "(['Apple Tart', 'Berry Tart'], 'Blueberry Tart', 0.257, 0.9589552238805971)\n",
      "(['Blueberry Tart', 'Berry Tart'], 'Apple Tart', 0.257, 0.9961240310077519)\n",
      "(['Blueberry Tart', 'Apple Tart'], 'Berry Tart', 0.257, 0.9922779922779923)\n"
     ]
    }
   ],
   "source": [
    "skylines_final_1000, rules_final_1000 = mine_bakery_rules(\"out2.csv\", .1, 0, \"goods.csv\")\n",
    "print(\"Skylines:\" + \"\\n\")\n",
    "for item in skylines_final_1000:\n",
    "    print(item)\n",
    "print()\n",
    "print(\"Association Rules:\" + \"\\n\")\n",
    "for item in rules_final_1000:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2b2561e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skylines:\n",
      "\n",
      "(['Chocolate Eclair'], 0.0382)\n",
      "(['Vanilla Eclair'], 0.046)\n",
      "(['Almond Tart'], 0.0386)\n",
      "(['Apricot Tart'], 0.0422)\n",
      "(['Pecan Tart'], 0.0444)\n",
      "(['Ganache Cookie'], 0.0388)\n",
      "(['Chocolate Meringue'], 0.0452)\n",
      "(['Vanilla Meringue'], 0.0398)\n",
      "(['Almond Croissant'], 0.0456)\n",
      "(['Chocolate Croissant'], 0.0432)\n",
      "(['Almond Bear Claw'], 0.0428)\n",
      "(['Blueberry Danish'], 0.04)\n",
      "(['Lemon Cake', 'Lemon Tart'], 0.0336)\n",
      "(['Napoleon Cake', 'Strawberry Cake'], 0.0422)\n",
      "(['Truffle Cake', 'Gongolais Cookie'], 0.0472)\n",
      "(['Bottled Water', 'Berry Tart'], 0.0366)\n",
      "(['Marzipan Cookie', 'Tuile Cookie'], 0.0496)\n",
      "(['Cheese Croissant', 'Orange Juice'], 0.043)\n",
      "(['Chocolate Cake', 'Casino Cake', 'Chocolate Coffee'], 0.0312)\n",
      "(['Apricot Danish', 'Cherry Tart', 'Opera Cake'], 0.0408)\n",
      "(['Single Espresso', 'Blackberry Tart', 'Coffee Eclair'], 0.0286)\n",
      "(['Blueberry Tart', 'Apricot Croissant', 'Hot Coffee'], 0.0328)\n",
      "(['Chocolate Tart', 'Walnut Cookie', 'Vanilla Frappuccino'], 0.0266)\n",
      "(['Almond Twist', 'Coffee Eclair', 'Apple Pie', 'Hot Coffee'], 0.0308)\n",
      "(['Cherry Soda', 'Apple Danish', 'Apple Tart', 'Apple Croissant'], 0.0228)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Green Tea', 'Raspberry Cookie', 'Lemon Cookie'], 0.0212)\n",
      "\n",
      "Association Rules:\n",
      "\n",
      "(['Casino Cake', 'Chocolate Coffee'], 'Chocolate Cake', 0.9017341040462428)\n",
      "(['Chocolate Cake', 'Casino Cake'], 'Chocolate Coffee', 0.9122807017543859)\n",
      "(['Cherry Tart', 'Opera Cake'], 'Apricot Danish', 0.9357798165137615)\n",
      "(['Opera Cake', 'Apricot Danish'], 'Cherry Tart', 0.9444444444444444)\n",
      "(['Single Espresso', 'Coffee Eclair'], 'Blackberry Tart', 0.9662162162162162)\n",
      "(['Single Espresso', 'Blackberry Tart'], 'Coffee Eclair', 0.910828025477707)\n",
      "(['Apricot Croissant', 'Hot Coffee'], 'Blueberry Tart', 0.9425287356321839)\n",
      "(['Blueberry Tart', 'Hot Coffee'], 'Apricot Croissant', 0.9371428571428572)\n",
      "(['Chocolate Tart', 'Walnut Cookie'], 'Vanilla Frappuccino', 0.9300699300699301)\n",
      "(['Apple Pie', 'Hot Coffee', 'Coffee Eclair'], 'Almond Twist', 1.0)\n",
      "(['Hot Coffee', 'Apple Pie', 'Almond Twist'], 'Coffee Eclair', 1.0)\n",
      "(['Hot Coffee', 'Almond Twist', 'Coffee Eclair'], 'Apple Pie', 1.0)\n",
      "(['Cherry Soda', 'Apple Tart', 'Apple Croissant'], 'Apple Danish', 0.991304347826087)\n",
      "(['Cherry Soda', 'Apple Danish', 'Apple Croissant'], 'Apple Tart', 0.991304347826087)\n",
      "(['Cherry Soda', 'Apple Danish', 'Apple Tart'], 'Apple Croissant', 1.0)\n",
      "(['Lemon Cookie', 'Raspberry Lemonade', 'Green Tea', 'Raspberry Cookie'], 'Lemon Lemonade', 1.0)\n",
      "(['Lemon Lemonade', 'Lemon Cookie', 'Green Tea', 'Raspberry Cookie'], 'Raspberry Lemonade', 1.0)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Green Tea', 'Lemon Cookie'], 'Raspberry Cookie', 1.0)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Green Tea', 'Raspberry Cookie'], 'Lemon Cookie', 1.0)\n"
     ]
    }
   ],
   "source": [
    "skylines_final_5000, rules_final_5000 = mine_bakery_rules(\"5000-out2.csv\", .01, .9, \"goods.csv\")\n",
    "print(\"Skylines:\" + \"\\n\")\n",
    "for item in skylines_final_5000:\n",
    "    print(item)\n",
    "print()\n",
    "print(\"Association Rules:\" + \"\\n\")\n",
    "for item in rules_final_5000:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc4bf1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skylines:\n",
      "\n",
      "(['Chocolate Eclair'], 0.0426)\n",
      "(['Vanilla Eclair'], 0.0427)\n",
      "(['Almond Tart'], 0.04055)\n",
      "(['Apricot Tart'], 0.04275)\n",
      "(['Pecan Tart'], 0.04155)\n",
      "(['Ganache Cookie'], 0.0433)\n",
      "(['Chocolate Meringue'], 0.0445)\n",
      "(['Vanilla Meringue'], 0.0424)\n",
      "(['Almond Croissant'], 0.04205)\n",
      "(['Chocolate Croissant'], 0.0446)\n",
      "(['Almond Bear Claw'], 0.04425)\n",
      "(['Blueberry Danish'], 0.04115)\n",
      "(['Lemon Cake', 'Lemon Tart'], 0.037)\n",
      "(['Napoleon Cake', 'Strawberry Cake'], 0.04455)\n",
      "(['Truffle Cake', 'Gongolais Cookie'], 0.04335)\n",
      "(['Bottled Water', 'Berry Tart'], 0.0357)\n",
      "(['Marzipan Cookie', 'Tuile Cookie'], 0.04855)\n",
      "(['Cheese Croissant', 'Orange Juice'], 0.0439)\n",
      "(['Chocolate Cake', 'Casino Cake', 'Chocolate Coffee'], 0.0339)\n",
      "(['Apricot Danish', 'Cherry Tart', 'Opera Cake'], 0.041)\n",
      "(['Single Espresso', 'Blackberry Tart', 'Coffee Eclair'], 0.02695)\n",
      "(['Blueberry Tart', 'Apricot Croissant', 'Hot Coffee'], 0.0326)\n",
      "(['Chocolate Tart', 'Walnut Cookie', 'Vanilla Frappuccino'], 0.02825)\n",
      "(['Almond Twist', 'Coffee Eclair', 'Apple Pie', 'Hot Coffee'], 0.0281)\n",
      "(['Cherry Soda', 'Apple Danish', 'Apple Tart', 'Apple Croissant'], 0.021)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Green Tea', 'Raspberry Cookie', 'Lemon Cookie'], 0.0204)\n",
      "\n",
      "Association Rules:\n",
      "\n",
      "(['Napoleon Cake'], 'Strawberry Cake', 0.5272189349112426)\n",
      "(['Truffle Cake'], 'Gongolais Cookie', 0.5121086828115771)\n",
      "(['Marzipan Cookie'], 'Tuile Cookie', 0.5615962984384038)\n",
      "(['Cheese Croissant'], 'Orange Juice', 0.5373317013463892)\n",
      "(['Casino Cake', 'Chocolate Coffee'], 'Chocolate Cake', 0.9495798319327731)\n",
      "(['Chocolate Cake', 'Chocolate Coffee'], 'Casino Cake', 0.7695800227014756)\n",
      "(['Chocolate Cake', 'Casino Cake'], 'Chocolate Coffee', 0.9456066945606695)\n",
      "(['Cherry Tart', 'Opera Cake'], 'Apricot Danish', 0.9392898052691867)\n",
      "(['Opera Cake', 'Apricot Danish'], 'Cherry Tart', 0.9457900807381776)\n",
      "(['Cherry Tart', 'Apricot Danish'], 'Opera Cake', 0.780209324452902)\n",
      "(['Coffee Eclair', 'Blackberry Tart'], 'Single Espresso', 0.7333333333333333)\n",
      "(['Single Espresso', 'Coffee Eclair'], 'Blackberry Tart', 0.9197952218430034)\n",
      "(['Single Espresso', 'Blackberry Tart'], 'Coffee Eclair', 0.8938640132669984)\n",
      "(['Apricot Croissant', 'Hot Coffee'], 'Blueberry Tart', 0.9287749287749287)\n",
      "(['Blueberry Tart', 'Hot Coffee'], 'Apricot Croissant', 0.9131652661064426)\n",
      "(['Blueberry Tart', 'Apricot Croissant'], 'Hot Coffee', 0.7789725209080047)\n",
      "(['Walnut Cookie', 'Vanilla Frappuccino'], 'Chocolate Tart', 0.9127625201938611)\n",
      "(['Chocolate Tart', 'Vanilla Frappuccino'], 'Walnut Cookie', 0.7687074829931972)\n",
      "(['Chocolate Tart', 'Walnut Cookie'], 'Vanilla Frappuccino', 0.9247135842880524)\n",
      "(['Apple Pie', 'Hot Coffee', 'Coffee Eclair'], 'Almond Twist', 0.9964539007092199)\n",
      "(['Hot Coffee', 'Apple Pie', 'Almond Twist'], 'Coffee Eclair', 0.9946902654867257)\n",
      "(['Hot Coffee', 'Almond Twist', 'Coffee Eclair'], 'Apple Pie', 0.9982238010657194)\n",
      "(['Apple Pie', 'Almond Twist', 'Coffee Eclair'], 'Hot Coffee', 0.8228404099560761)\n",
      "(['Apple Danish', 'Apple Tart', 'Apple Croissant'], 'Cherry Soda', 0.8076923076923077)\n",
      "(['Cherry Soda', 'Apple Tart', 'Apple Croissant'], 'Apple Danish', 0.9929078014184397)\n",
      "(['Cherry Soda', 'Apple Danish', 'Apple Croissant'], 'Apple Tart', 0.9882352941176471)\n",
      "(['Cherry Soda', 'Apple Danish', 'Apple Tart'], 'Apple Croissant', 0.995260663507109)\n",
      "(['Lemon Cookie', 'Raspberry Lemonade', 'Green Tea', 'Raspberry Cookie'], 'Lemon Lemonade', 1.0)\n",
      "(['Lemon Lemonade', 'Lemon Cookie', 'Green Tea', 'Raspberry Cookie'], 'Raspberry Lemonade', 1.0)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Lemon Cookie', 'Raspberry Cookie'], 'Green Tea', 0.8015717092337917)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Green Tea', 'Lemon Cookie'], 'Raspberry Cookie', 0.9975550122249389)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Green Tea', 'Raspberry Cookie'], 'Lemon Cookie', 0.9975550122249389)\n"
     ]
    }
   ],
   "source": [
    "skylines_final_20000, rules_final_20000 = mine_bakery_rules(\"20000-out2.csv\", .01, .5, \"goods.csv\")\n",
    "print(\"Skylines:\" + \"\\n\")\n",
    "for item in skylines_final_20000:\n",
    "    print(item)\n",
    "print()\n",
    "print(\"Association Rules:\" + \"\\n\")\n",
    "for item in rules_final_20000:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0eeb7ea-1dc4-4ddc-a260-415fa9c43b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skylines:\n",
      "\n",
      "(['Chocolate Eclair'], 0.04237333333333333)\n",
      "(['Vanilla Eclair'], 0.04252)\n",
      "(['Almond Tart'], 0.04204)\n",
      "(['Apricot Tart'], 0.04236)\n",
      "(['Pecan Tart'], 0.04337333333333333)\n",
      "(['Ganache Cookie'], 0.04324)\n",
      "(['Chocolate Meringue'], 0.041933333333333336)\n",
      "(['Vanilla Meringue'], 0.04238666666666667)\n",
      "(['Almond Croissant'], 0.04273333333333333)\n",
      "(['Chocolate Croissant'], 0.04324)\n",
      "(['Almond Bear Claw'], 0.04244)\n",
      "(['Blueberry Danish'], 0.04409333333333333)\n",
      "(['Lemon Cake', 'Lemon Tart'], 0.036853333333333335)\n",
      "(['Napoleon Cake', 'Strawberry Cake'], 0.043146666666666667)\n",
      "(['Truffle Cake', 'Gongolais Cookie'], 0.04392)\n",
      "(['Bottled Water', 'Berry Tart'], 0.0378)\n",
      "(['Marzipan Cookie', 'Tuile Cookie'], 0.05092)\n",
      "(['Cheese Croissant', 'Orange Juice'], 0.04306666666666667)\n",
      "(['Chocolate Cake', 'Casino Cake', 'Chocolate Coffee'], 0.03338666666666667)\n",
      "(['Apricot Danish', 'Cherry Tart', 'Opera Cake'], 0.041106666666666666)\n",
      "(['Single Espresso', 'Blackberry Tart', 'Coffee Eclair'], 0.0272)\n",
      "(['Blueberry Tart', 'Apricot Croissant', 'Hot Coffee'], 0.032826666666666664)\n",
      "(['Chocolate Tart', 'Walnut Cookie', 'Vanilla Frappuccino'], 0.02676)\n",
      "(['Almond Twist', 'Coffee Eclair', 'Apple Pie', 'Hot Coffee'], 0.02792)\n",
      "(['Cherry Soda', 'Apple Danish', 'Apple Tart', 'Apple Croissant'], 0.020586666666666666)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Green Tea', 'Raspberry Cookie', 'Lemon Cookie'], 0.020733333333333333)\n",
      "\n",
      "Association Rules:\n",
      "\n",
      "(['Napoleon Cake'], 'Strawberry Cake', 0.5214308733483726)\n",
      "(['Truffle Cake'], 'Gongolais Cookie', 0.5340466926070039)\n",
      "(['Bottled Water'], 'Berry Tart', 0.5026595744680851)\n",
      "(['Tuile Cookie'], 'Marzipan Cookie', 0.5054261514028586)\n",
      "(['Marzipan Cookie'], 'Tuile Cookie', 0.5672062973414526)\n",
      "(['Cheese Croissant'], 'Orange Juice', 0.5238404151800194)\n",
      "(['Casino Cake', 'Chocolate Coffee'], 'Chocolate Cake', 0.9474082482027999)\n",
      "(['Chocolate Cake', 'Chocolate Coffee'], 'Casino Cake', 0.7580986981531941)\n",
      "(['Chocolate Cake', 'Casino Cake'], 'Chocolate Coffee', 0.9395872420262664)\n",
      "(['Cherry Tart', 'Opera Cake'], 'Apricot Danish', 0.9477405471872118)\n",
      "(['Opera Cake', 'Apricot Danish'], 'Cherry Tart', 0.9553765106910443)\n",
      "(['Cherry Tart', 'Apricot Danish'], 'Opera Cake', 0.7742340532395781)\n",
      "(['Coffee Eclair', 'Blackberry Tart'], 'Single Espresso', 0.74697912852435)\n",
      "(['Single Espresso', 'Coffee Eclair'], 'Blackberry Tart', 0.9222423146473779)\n",
      "(['Single Espresso', 'Blackberry Tart'], 'Coffee Eclair', 0.9230769230769231)\n",
      "(['Apricot Croissant', 'Hot Coffee'], 'Blueberry Tart', 0.9280060309084056)\n",
      "(['Blueberry Tart', 'Hot Coffee'], 'Apricot Croissant', 0.936834094368341)\n",
      "(['Blueberry Tart', 'Apricot Croissant'], 'Hot Coffee', 0.754520380018388)\n",
      "(['Walnut Cookie', 'Vanilla Frappuccino'], 'Chocolate Tart', 0.9396067415730337)\n",
      "(['Chocolate Tart', 'Vanilla Frappuccino'], 'Walnut Cookie', 0.7441601779755284)\n",
      "(['Chocolate Tart', 'Walnut Cookie'], 'Vanilla Frappuccino', 0.9369747899159664)\n",
      "(['Apple Pie', 'Hot Coffee', 'Coffee Eclair'], 'Almond Twist', 0.9938300901756051)\n",
      "(['Hot Coffee', 'Apple Pie', 'Almond Twist'], 'Coffee Eclair', 0.9952471482889734)\n",
      "(['Hot Coffee', 'Almond Twist', 'Coffee Eclair'], 'Apple Pie', 0.9928876244665719)\n",
      "(['Apple Pie', 'Almond Twist', 'Coffee Eclair'], 'Hot Coffee', 0.8135198135198135)\n",
      "(['Apple Danish', 'Apple Tart', 'Apple Croissant'], 'Cherry Soda', 0.807109252483011)\n",
      "(['Cherry Soda', 'Apple Tart', 'Apple Croissant'], 'Apple Danish', 0.9910141206675225)\n",
      "(['Cherry Soda', 'Apple Danish', 'Apple Croissant'], 'Apple Tart', 0.9897435897435898)\n",
      "(['Cherry Soda', 'Apple Danish', 'Apple Tart'], 'Apple Croissant', 0.9929260450160772)\n",
      "(['Lemon Cookie', 'Raspberry Lemonade', 'Green Tea', 'Raspberry Cookie'], 'Lemon Lemonade', 1.0)\n",
      "(['Lemon Lemonade', 'Lemon Cookie', 'Green Tea', 'Raspberry Cookie'], 'Raspberry Lemonade', 1.0)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Lemon Cookie', 'Raspberry Cookie'], 'Green Tea', 0.8111632759520083)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Green Tea', 'Lemon Cookie'], 'Raspberry Cookie', 1.0)\n",
      "(['Lemon Lemonade', 'Raspberry Lemonade', 'Green Tea', 'Raspberry Cookie'], 'Lemon Cookie', 0.9993573264781491)\n"
     ]
    }
   ],
   "source": [
    "skylines_final_75000, rules_final_75000 = mine_bakery_rules(\"75000-out2.csv\", .01, .5, \"goods.csv\")\n",
    "print(\"Skylines:\" + \"\\n\")\n",
    "for item in skylines_final_75000:\n",
    "    print(item)\n",
    "print()\n",
    "print(\"Association Rules:\" + \"\\n\")\n",
    "for item in rules_final_75000:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a4b83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_reader_rules(filename, minRelativeSup, minConf, author_filename, verbose=False):\n",
    "    #reading in reader dataset as dictionary\n",
    "    f = open(filename, \"r\")\n",
    "    read_dict = {}\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = [tok.strip() for tok in line.split(\",\")]\n",
    "        read_dict[int(tokens[0])] = [int(tok) for tok in tokens[1:]]\n",
    "        \n",
    "    #reading in author dataset as dictionary\n",
    "    f = open(author_filename, \"r\")\n",
    "    lines = f.readlines()\n",
    "    author_dict = {}\n",
    "    for line in lines:\n",
    "        tokens = [tok.strip() for tok in line.split(\"|\")]\n",
    "        author_dict[int(tokens[0])] = tokens[1]\n",
    "        \n",
    "    #converting to binary vector format\n",
    "    read_df_dict = {}\n",
    "    for reader in read_dict.keys():\n",
    "        binary_vector = np.zeros(len(author_dict.keys()))\n",
    "        for idx in read_dict[reader]:\n",
    "            binary_vector[idx-1] = 1\n",
    "        read_df_dict[reader] = binary_vector\n",
    "    reader_df = pd.DataFrame(read_df_dict, index=author_dict.keys(), dtype=\"int\").transpose()\n",
    "    reader_df = reader_df.drop(1,1) #drop the NA column\n",
    "    \n",
    "    #apriori and association rules\n",
    "    supports_dict,skyline_list = apriori(reader_df, list(reader_df.columns), minRelativeSup)\n",
    "    association_rules_dict = association_rules(supports_dict, skyline_list, minConf)\n",
    "    \n",
    "    #formatting skyline frequent item sets\n",
    "    skylines_formatted = []\n",
    "    for entry in skyline_list:\n",
    "        skyline_set = [author_dict[i] for i in entry]\n",
    "        support = supports_dict[len(entry)][entry]/reader_df.shape[0]\n",
    "        skylines_formatted.append((skyline_set, support))\n",
    "        \n",
    "    #formatting association rules\n",
    "    arules_formatted = []\n",
    "    for entry in association_rules_dict.keys():\n",
    "        left_side = [author_dict[i] for i in entry[0]]\n",
    "        right_side = author_dict[entry[1]]\n",
    "        total_itemset = entry[0].union([entry[1]])\n",
    "        support = supports_dict[len(total_itemset)][total_itemset]/reader_df.shape[0]\n",
    "        confidence = association_rules_dict[entry]\n",
    "        arules_formatted.append((left_side, right_side, support, confidence))\n",
    "    return skylines_formatted, arules_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8395d7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skylines:\n",
      "\n",
      "(['Aaronovitch, Ben'], 0.10699588477366255)\n",
      "(['Abraham, Daniel / Hanover, M. L. N. / Corey, James S. A.'], 0.07818930041152264)\n",
      "(['Anders, Charlie Jane'], 0.11522633744855967)\n",
      "(['Atwood, Margaret'], 0.09876543209876543)\n",
      "(['Bardugo, Leigh'], 0.102880658436214)\n",
      "(['Bear, Elizabeth'], 0.11934156378600823)\n",
      "(['Beaulieu, Bradley P.'], 0.10699588477366255)\n",
      "(['Bennett, Robert Jackson'], 0.12757201646090535)\n",
      "(['Brown, Pierce'], 0.102880658436214)\n",
      "(['Bujold, Lois McMaster'], 0.09053497942386832)\n",
      "(['Butler, Octavia E.'], 0.09053497942386832)\n",
      "(['Carriger, Gail'], 0.08641975308641975)\n",
      "(['Drake, Darrell'], 0.11934156378600823)\n",
      "(['Elliott, Kate / Rasmussen, Alis A.'], 0.08641975308641975)\n",
      "(['Erikson, Steven'], 0.08641975308641975)\n",
      "(['Huff, Tanya'], 0.0823045267489712)\n",
      "(['Jones, Diana Wynne'], 0.11522633744855967)\n",
      "(['Kowal, Mary Robinette'], 0.1111111111111111)\n",
      "(['Lee, Yoon Ha'], 0.09876543209876543)\n",
      "(['Liu, Ken'], 0.102880658436214)\n",
      "(['Liu, Marjorie'], 0.08641975308641975)\n",
      "(['Malerman, Josh'], 0.07818930041152264)\n",
      "(['Martin, George R. R.'], 0.09053497942386832)\n",
      "(['McCaffrey, Anne'], 0.07818930041152264)\n",
      "(['McGuire, Seanan / Grant, Mira'], 0.13991769547325103)\n",
      "(['Okorafor, Nnedi'], 0.09053497942386832)\n",
      "(['Patrick, Benedict'], 0.09876543209876543)\n",
      "(['Rothfuss, Patrick'], 0.07818930041152264)\n",
      "(['Schafer, Courtney'], 0.16049382716049382)\n",
      "(['Schwab, V. E. / Schwab, Victoria'], 0.13991769547325103)\n",
      "(['Smith, Sherwood'], 0.11934156378600823)\n",
      "(['Stiefvater, Maggie'], 0.102880658436214)\n",
      "(['Vaughan, Brian K.'], 0.12345679012345678)\n",
      "(['Villoso, K. S.'], 0.08641975308641975)\n",
      "(['Walton, Jo'], 0.12757201646090535)\n",
      "(['Wecker, Helene'], 0.12345679012345678)\n",
      "(['Wells, Martha'], 0.09053497942386832)\n",
      "(['Wolfe, Gene'], 0.09876543209876543)\n",
      "(['Wurts, Janny'], 0.13580246913580246)\n",
      "(['Zelazny, Roger'], 0.13580246913580246)\n",
      "(['Aaron, Rachel / Bach, Rachel', 'Bancroft, Josiah'], 0.09465020576131687)\n",
      "(['Aaron, Rachel / Bach, Rachel', 'VanderMeer, Jeff'], 0.08641975308641975)\n",
      "(['Bancroft, Josiah', 'Abercrombie, Joe'], 0.10699588477366255)\n",
      "(['Eames, Nicholas', 'Abercrombie, Joe'], 0.0823045267489712)\n",
      "(['Gaiman, Neil', 'Abercrombie, Joe'], 0.09876543209876543)\n",
      "(['Abercrombie, Joe', 'Lawrence, Mark'], 0.09876543209876543)\n",
      "(['Pratchett, Terry', 'Abercrombie, Joe'], 0.07818930041152264)\n",
      "(['Sanderson, Brandon', 'Abercrombie, Joe'], 0.1111111111111111)\n",
      "(['Addison, Katherine / Monette, Sarah', 'Gaiman, Neil'], 0.09876543209876543)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Addison, Katherine / Monette, Sarah'], 0.09465020576131687)\n",
      "(['Jemisin, N. K.', 'Addison, Katherine / Monette, Sarah'], 0.0823045267489712)\n",
      "(['Addison, Katherine / Monette, Sarah', 'Lawrence, Mark'], 0.10699588477366255)\n",
      "(['McClellan, Brian', 'Addison, Katherine / Monette, Sarah'], 0.0823045267489712)\n",
      "(['Novik, Naomi', 'Addison, Katherine / Monette, Sarah'], 0.09053497942386832)\n",
      "(['Pratchett, Terry', 'Addison, Katherine / Monette, Sarah'], 0.0823045267489712)\n",
      "(['VanderMeer, Jeff', 'Addison, Katherine / Monette, Sarah'], 0.07818930041152264)\n",
      "(['Arden, Katherine', 'Hobb, Robin / Lindholm, Megan'], 0.07818930041152264)\n",
      "(['Arden, Katherine', 'Jemisin, N. K.'], 0.11522633744855967)\n",
      "(['Ball, Krista D. / Ball, K.', 'Jemisin, N. K.'], 0.09053497942386832)\n",
      "(['Bancroft, Josiah', 'Brennan, Marie'], 0.11522633744855967)\n",
      "(['Bancroft, Josiah', 'Butcher, Jim'], 0.07818930041152264)\n",
      "(['Chambers, Becky', 'Bancroft, Josiah'], 0.10699588477366255)\n",
      "(['Bancroft, Josiah', 'Gladstone, Max'], 0.08641975308641975)\n",
      "(['Hawkins, Scott', 'Bancroft, Josiah'], 0.09053497942386832)\n",
      "(['Bancroft, Josiah', 'Herbert, Frank'], 0.08641975308641975)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Bancroft, Josiah'], 0.13168724279835392)\n",
      "(['Hurley, Kameron', 'Bancroft, Josiah'], 0.07818930041152264)\n",
      "(['Bancroft, Josiah', 'Kay, Guy Gavriel'], 0.08641975308641975)\n",
      "(['Bancroft, Josiah', 'King, Stephen'], 0.09465020576131687)\n",
      "(['Bancroft, Josiah', 'Le Guin, Ursula K.'], 0.08641975308641975)\n",
      "(['Lynch, Scott', 'Bancroft, Josiah'], 0.10699588477366255)\n",
      "(['McClellan, Brian', 'Bancroft, Josiah'], 0.0823045267489712)\n",
      "(['Mieville, China', 'Bancroft, Josiah'], 0.11934156378600823)\n",
      "(['Bancroft, Josiah', 'Rowe, Andrew'], 0.11522633744855967)\n",
      "(['Sullivan, Michael J.', 'Bancroft, Josiah'], 0.13580246913580246)\n",
      "(['Bancroft, Josiah', 'Valente, Catherynne M.'], 0.08641975308641975)\n",
      "(['VanderMeer, Jeff', 'Bancroft, Josiah'], 0.1111111111111111)\n",
      "(['Gladstone, Max', 'Brennan, Marie'], 0.07818930041152264)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Brennan, Marie'], 0.0823045267489712)\n",
      "(['Jemisin, N. K.', 'Brennan, Marie'], 0.13580246913580246)\n",
      "(['Mieville, China', 'Brennan, Marie'], 0.09053497942386832)\n",
      "(['Novik, Naomi', 'Brennan, Marie'], 0.07818930041152264)\n",
      "(['Sanderson, Brandon', 'Brennan, Marie'], 0.09053497942386832)\n",
      "(['Brennan, Marie', 'Valente, Catherynne M.'], 0.09876543209876543)\n",
      "(['Butcher, Jim', 'Lawrence, Mark'], 0.08641975308641975)\n",
      "(['Sanderson, Brandon', 'Butcher, Jim'], 0.10699588477366255)\n",
      "(['Chambers, Becky', 'Jemisin, N. K.'], 0.08641975308641975)\n",
      "(['Chambers, Becky', 'Sanderson, Brandon'], 0.09876543209876543)\n",
      "(['Eames, Nicholas', 'Gaiman, Neil'], 0.09053497942386832)\n",
      "(['Eames, Nicholas', 'Jemisin, N. K.'], 0.09053497942386832)\n",
      "(['Eames, Nicholas', 'Lawrence, Mark'], 0.11522633744855967)\n",
      "(['Eames, Nicholas', 'Lynch, Scott'], 0.09053497942386832)\n",
      "(['Eames, Nicholas', 'Mieville, China'], 0.09876543209876543)\n",
      "(['Eames, Nicholas', 'Pratchett, Terry'], 0.07818930041152264)\n",
      "(['Eames, Nicholas', 'Sullivan, Michael J.'], 0.08641975308641975)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Gaiman, Neil'], 0.0823045267489712)\n",
      "(['Jemisin, N. K.', 'Gaiman, Neil'], 0.09465020576131687)\n",
      "(['Lynch, Scott', 'Gaiman, Neil'], 0.09465020576131687)\n",
      "(['Mieville, China', 'Gaiman, Neil'], 0.0823045267489712)\n",
      "(['Novik, Naomi', 'Gaiman, Neil'], 0.09465020576131687)\n",
      "(['Pratchett, Terry', 'Gaiman, Neil'], 0.11934156378600823)\n",
      "(['Rowe, Andrew', 'Gaiman, Neil'], 0.09053497942386832)\n",
      "(['Sullivan, Michael J.', 'Gaiman, Neil'], 0.09876543209876543)\n",
      "(['VanderMeer, Jeff', 'Gaiman, Neil'], 0.09876543209876543)\n",
      "(['Gladstone, Max', 'Sanderson, Brandon'], 0.09053497942386832)\n",
      "(['Herbert, Frank', 'Pratchett, Terry'], 0.07818930041152264)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Jemisin, N. K.'], 0.12345679012345678)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'King, Stephen'], 0.09465020576131687)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Lawrence, Mark'], 0.10699588477366255)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Lynch, Scott'], 0.0823045267489712)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Mieville, China'], 0.09876543209876543)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Novik, Naomi'], 0.08641975308641975)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Pratchett, Terry'], 0.0823045267489712)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Rowe, Andrew'], 0.0823045267489712)\n",
      "(['Hobb, Robin / Lindholm, Megan', 'Sanderson, Brandon'], 0.12757201646090535)\n",
      "(['Jemisin, N. K.', 'Lawrence, Mark'], 0.09876543209876543)\n",
      "(['Le Guin, Ursula K.', 'Jemisin, N. K.'], 0.10699588477366255)\n",
      "(['Mieville, China', 'Jemisin, N. K.'], 0.09053497942386832)\n",
      "(['Novik, Naomi', 'Jemisin, N. K.'], 0.11934156378600823)\n",
      "(['Jemisin, N. K.', 'Pratchett, Terry'], 0.0823045267489712)\n",
      "(['Sullivan, Michael J.', 'Jemisin, N. K.'], 0.0823045267489712)\n",
      "(['Jemisin, N. K.', 'Valente, Catherynne M.'], 0.11522633744855967)\n",
      "(['VanderMeer, Jeff', 'Jemisin, N. K.'], 0.08641975308641975)\n",
      "(['King, Stephen', 'Lawrence, Mark'], 0.07818930041152264)\n",
      "(['Sanderson, Brandon', 'King, Stephen'], 0.102880658436214)\n",
      "(['Lynch, Scott', 'Lawrence, Mark'], 0.09465020576131687)\n",
      "(['Novik, Naomi', 'Lawrence, Mark'], 0.0823045267489712)\n",
      "(['Pratchett, Terry', 'Lawrence, Mark'], 0.10699588477366255)\n",
      "(['Rowe, Andrew', 'Lawrence, Mark'], 0.11522633744855967)\n",
      "(['Sullivan, Michael J.', 'Lawrence, Mark'], 0.09876543209876543)\n",
      "(['VanderMeer, Jeff', 'Lawrence, Mark'], 0.11522633744855967)\n",
      "(['Mieville, China', 'Le Guin, Ursula K.'], 0.07818930041152264)\n",
      "(['Le Guin, Ursula K.', 'Sanderson, Brandon'], 0.09053497942386832)\n",
      "(['Lynch, Scott', 'Pratchett, Terry'], 0.09876543209876543)\n",
      "(['Lynch, Scott', 'Sanderson, Brandon'], 0.09876543209876543)\n",
      "(['Lynch, Scott', 'VanderMeer, Jeff'], 0.07818930041152264)\n",
      "(['McClellan, Brian', 'Sanderson, Brandon'], 0.1111111111111111)\n",
      "(['Mieville, China', 'Pratchett, Terry'], 0.09053497942386832)\n",
      "(['Mieville, China', 'Sanderson, Brandon'], 0.1111111111111111)\n",
      "(['North, Claire / Webb, Catherine / Griffin, Kate', 'Sanderson, Brandon'], 0.0823045267489712)\n",
      "(['Novik, Naomi', 'Pratchett, Terry'], 0.0823045267489712)\n",
      "(['Novik, Naomi', 'Rowe, Andrew'], 0.0823045267489712)\n",
      "(['Rowe, Andrew', 'Pratchett, Terry'], 0.0823045267489712)\n",
      "(['Sullivan, Michael J.', 'Pratchett, Terry'], 0.09465020576131687)\n",
      "(['VanderMeer, Jeff', 'Pratchett, Terry'], 0.09053497942386832)\n",
      "(['Sanderson, Brandon', 'Rowe, Andrew'], 0.13991769547325103)\n",
      "(['Sullivan, Michael J.', 'Sanderson, Brandon'], 0.13168724279835392)\n",
      "(['VanderMeer, Jeff', 'Sanderson, Brandon'], 0.1111111111111111)\n",
      "(['Sanderson, Brandon', 'Willis, Connie'], 0.07818930041152264)\n",
      "(['Bancroft, Josiah', 'Sanderson, Brandon', 'Addison, Katherine / Monette, Sarah'], 0.08641975308641975)\n",
      "(['Eames, Nicholas', 'Bancroft, Josiah', 'Sanderson, Brandon'], 0.0823045267489712)\n",
      "(['Bancroft, Josiah', 'Gaiman, Neil', 'Lawrence, Mark'], 0.0823045267489712)\n",
      "(['Bancroft, Josiah', 'Sanderson, Brandon', 'Gaiman, Neil'], 0.07818930041152264)\n",
      "(['Bancroft, Josiah', 'Jemisin, N. K.', 'Sanderson, Brandon'], 0.09053497942386832)\n",
      "(['Bancroft, Josiah', 'Sanderson, Brandon', 'Lawrence, Mark'], 0.08641975308641975)\n",
      "(['Novik, Naomi', 'Bancroft, Josiah', 'Sanderson, Brandon'], 0.09465020576131687)\n",
      "(['Bancroft, Josiah', 'Sanderson, Brandon', 'Pratchett, Terry'], 0.0823045267489712)\n",
      "\n",
      "Association Rules:\n",
      "\n",
      "(['Abercrombie, Joe'], 'Bancroft, Josiah', 0.10699588477366255, 0.5909090909090909)\n",
      "(['Abercrombie, Joe'], 'Gaiman, Neil', 0.09876543209876543, 0.5454545454545454)\n",
      "(['Abercrombie, Joe'], 'Lawrence, Mark', 0.09876543209876543, 0.5454545454545454)\n",
      "(['Abercrombie, Joe'], 'Sanderson, Brandon', 0.1111111111111111, 0.6136363636363636)\n",
      "(['Arden, Katherine'], 'Jemisin, N. K.', 0.11522633744855967, 0.56)\n",
      "(['Chambers, Becky'], 'Bancroft, Josiah', 0.10699588477366255, 0.52)\n",
      "(['Hawkins, Scott'], 'Bancroft, Josiah', 0.09053497942386832, 0.6470588235294118)\n",
      "(['Herbert, Frank'], 'Bancroft, Josiah', 0.08641975308641975, 0.6774193548387096)\n",
      "(['Hurley, Kameron'], 'Bancroft, Josiah', 0.07818930041152264, 0.5757575757575758)\n",
      "(['Kay, Guy Gavriel'], 'Bancroft, Josiah', 0.08641975308641975, 0.6363636363636364)\n",
      "(['King, Stephen'], 'Bancroft, Josiah', 0.09465020576131687, 0.5227272727272727)\n",
      "(['Lynch, Scott'], 'Bancroft, Josiah', 0.10699588477366255, 0.5416666666666666)\n",
      "(['Sullivan, Michael J.'], 'Bancroft, Josiah', 0.13580246913580246, 0.5892857142857143)\n",
      "(['Butcher, Jim'], 'Lawrence, Mark', 0.08641975308641975, 0.5384615384615384)\n",
      "(['Butcher, Jim'], 'Sanderson, Brandon', 0.10699588477366255, 0.6666666666666666)\n",
      "(['Herbert, Frank'], 'Pratchett, Terry', 0.07818930041152264, 0.6129032258064516)\n",
      "(['King, Stephen'], 'Hobb, Robin / Lindholm, Megan', 0.09465020576131687, 0.5227272727272727)\n",
      "(['Valente, Catherynne M.'], 'Jemisin, N. K.', 0.11522633744855967, 0.56)\n",
      "(['King, Stephen'], 'Sanderson, Brandon', 0.102880658436214, 0.5681818181818182)\n",
      "(['McClellan, Brian'], 'Sanderson, Brandon', 0.1111111111111111, 0.6428571428571429)\n",
      "(['North, Claire / Webb, Catherine / Griffin, Kate'], 'Sanderson, Brandon', 0.0823045267489712, 0.5555555555555556)\n",
      "(['Rowe, Andrew'], 'Sanderson, Brandon', 0.13991769547325103, 0.576271186440678)\n",
      "(['Sullivan, Michael J.'], 'Sanderson, Brandon', 0.13168724279835392, 0.5714285714285714)\n",
      "(['Willis, Connie'], 'Sanderson, Brandon', 0.07818930041152264, 0.5428571428571428)\n",
      "(['Addison, Katherine / Monette, Sarah', 'Sanderson, Brandon'], 'Bancroft, Josiah', 0.08641975308641975, 0.6)\n",
      "(['Bancroft, Josiah', 'Addison, Katherine / Monette, Sarah'], 'Sanderson, Brandon', 0.08641975308641975, 0.6176470588235294)\n",
      "(['Eames, Nicholas', 'Sanderson, Brandon'], 'Bancroft, Josiah', 0.0823045267489712, 0.6451612903225806)\n",
      "(['Eames, Nicholas', 'Bancroft, Josiah'], 'Sanderson, Brandon', 0.0823045267489712, 0.5882352941176471)\n",
      "(['Gaiman, Neil', 'Lawrence, Mark'], 'Bancroft, Josiah', 0.0823045267489712, 0.6896551724137931)\n",
      "(['Bancroft, Josiah', 'Gaiman, Neil'], 'Lawrence, Mark', 0.0823045267489712, 0.625)\n",
      "(['Sanderson, Brandon', 'Gaiman, Neil'], 'Bancroft, Josiah', 0.07818930041152264, 0.5135135135135135)\n",
      "(['Bancroft, Josiah', 'Gaiman, Neil'], 'Sanderson, Brandon', 0.07818930041152264, 0.59375)\n",
      "(['Jemisin, N. K.', 'Sanderson, Brandon'], 'Bancroft, Josiah', 0.09053497942386832, 0.5365853658536586)\n",
      "(['Bancroft, Josiah', 'Jemisin, N. K.'], 'Sanderson, Brandon', 0.09053497942386832, 0.6285714285714286)\n",
      "(['Sanderson, Brandon', 'Lawrence, Mark'], 'Bancroft, Josiah', 0.08641975308641975, 0.5384615384615384)\n",
      "(['Novik, Naomi', 'Sanderson, Brandon'], 'Bancroft, Josiah', 0.09465020576131687, 0.6388888888888888)\n",
      "(['Novik, Naomi', 'Bancroft, Josiah'], 'Sanderson, Brandon', 0.09465020576131687, 0.6571428571428571)\n",
      "(['Pratchett, Terry', 'Sanderson, Brandon'], 'Bancroft, Josiah', 0.0823045267489712, 0.5882352941176471)\n"
     ]
    }
   ],
   "source": [
    "skylines_final, rules_final = mine_reader_rules(\"bingoBaskets.csv\", .075, .5, \"authorlist.psv\")\n",
    "print(\"Skylines:\" + \"\\n\")\n",
    "for item in skylines_final:\n",
    "    print(item)\n",
    "print()\n",
    "print(\"Association Rules:\" + \"\\n\")\n",
    "for item in rules_final:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a399e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
